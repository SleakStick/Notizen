\documentclass{article}
\title{Analysis II Einsiedler Version}
\author{Benjamin Dropmann}
\usepackage{geometry}
\usepackage{xcolor}
\usepackage{amssymb}
\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{multicol}
\usepackage{titlesec}
\titlespacing*{\subsubsection}{0pt}{1.2ex}{.1ex plus .2ex minus .2ex}

\newcommand{\mspc}{\hspace{0.7cm}}
\newcommand{\smspc}{\hspace{0.3cm}}

\newcommand{\kk}[1]{\left<\left<{#1}\right>\right>}
\newcommand{\dd}[1]{\hspace{0.2cm}\text{d{#1}}}

\newcommand{\satz}[1]{\subsubsection*{Satz {#1}}}
\newcommand{\korollar}[1]{\subsubsection*{Korollar {#1}}}
\newcommand{\beweis}{\\\textbf{Beweis }}
\newcommand{\beispiel}[1]{\subsubsection*{Beispiele {#1}}}
\newcommand{\bemerkung}[1]{\subsubsection*{Bemerkung {#1}}}
\newcommand{\theorem}[1]{\subsubsection*{Theorem {#1}}}
\newcommand{\lemma}[1]{\subsubsection*{Lemma {#1}}}
\newcommand{\definition}[1]{\subsubsection*{Definition {#1}}}
\newcommand{\behauptung}[1]{\subsubsection*{Behauptung {#1}}}

\geometry{margin=1.5cm}
\begin{document}
\maketitle
\section{Wiederholung}
\definition{Taylor-Polynom} Sei eine funktion $f:(a,b)\rightarrow\mathbb{C}$ um einen punkt $x_0\in (a,b)$ die $n$-mal differenzierbar ist. Dann ist der Polynom 
\[p_{x_0,n}^f(x)=\sin_{k=0}^n\frac{f^{(k)}(x_0)}{k!}(x-x_0)\]
\satz{Taylor Approximation} sei $f:(a,b)\rightarrow\mathbb{C}$ eine $n+1$ mal stetig differenzierbare funktion und $x_0,x\in (a,b)$ dann gilt\[f(x)=P_{x_0,n}^f(x)+R_{x_0,n}^f(x)\]
Wobei diese $R_{x_0,n}^f(x)$ der restglied ist und ich den mit \[R_{x_0,n}^f(x)=\int_{x_0}^xf^{(x+1)}(t)\frac{(x-t)^n}{n!}\dd{t}\]
Für $M_{n+1}=\max\lbrace |f^{(n+1)}(t)|$ mit $t\in (x,x_0)$ gilt $|R_{x_0,n}^f(x)|\le\frac{M_{n+1}|x-x_0|}{(n+1)!}$
\definition{} Eine Funktion $f(a,b)\rightarrow\mathbb{C}$ heisst analytisch falls es zu jedem $x_0\in (a,b)$ $\exists R>0$ so dass \[f(x)=\sum_{n=0}^\infty \frac{f^{(n)}(x_0)}{n!}(x-x_=)!\smspc\forall x:|x-x_0|<R\]
\subsection*{8.6 Numerische Integration}
\satz{} Sei $f:[a,b]\rightarrow\mathbb{R}$ ,ot $n\in \mathbb{N}$ und $h=\frac{b-a}{h}$, $x_e=a+lh$ für  $l\in\lbrace  0,1,\cdots,n\rbrace$  Falls $f$ stetig differenzierbar  ist dann gilt \[\int_a^b f(t)\dd{t}=h\cdot(f(x_0)+f(x_1)+\cdots+f(x_{n-1}))+F_1\] Wobei $F_1$ unser fehler ist: $F_1\le \frac{M_1(b-1)^2}{2n}$
mit $M_1=\max\lbrace|f'(x)|:x\in[a,b]\rbrace$
Falls die Funktion $2$-mal stetig differenzierbar ist dann gilt: 
\[\int_a^bf(t)\dd{t}=\frac{h}{2}\left(f(x_0)+2f(x_1)+\cdots+2f(x_{n-1}))+f(x_n)\right)+F_2\mspc F_2=\frac{M_2(b-a)^3}{6n^2}\]
Man kann auch für $f$ vier mal differenzierbar und $n$ gerade eine solche abschätzung machen, dies ist die Simpson Regel:
\[\int_a^b f(t)\dd{t}=\frac{h}{3}\left(f(x_0)+4f(x_1)+2f(x_2)+4f(x_3)+\cdots+4f(x_{n-1})+f(x_n)\right)+F_4\mspc F_4\le\frac{M_4(b-1)^5}{45n^4}\]
\section*{9. Metrische Räume}
\subsection*{9.1 Konvergenz in Metrische Räume}
\definition{Metrischer Raum} Ein Metrischer Raum ist eine Menge $X$ mit eine Abbildung $d:X\times X\rightarrow \mathbb{R}_{\ge 0}$ Mit folgende Eigenschaften
\begin{itemize}
  \item[i.]{\textbf{Definitheit} $\forall x,y\in X$ gilt $d(x,y)=0\Leftrightarrow x_y$}
  \item[ii.]{\textbf{Symmetrie} $d(x,y)=d(y,x)\smspc\forall x,y\in X$}
  \item[iii.]{\textbf{Dreiecksungleichung} $\forall x,y,z\in X$ gilt $d(x,z)\le d(x,y)+d(y,z)$}
\end{itemize}
Das $d$ hier ist einfach eine Abstandsfunktion, die einen Abstand zwischen zwei elemente der Menge anteilt. Diese Abbildung ist die Metrik.
$X$ kann $\mathbb{R}$, $\mathbb{C}$ oder sogar $\mathbb{R}^n$ sein, die Metrik $d$ kann irgendeine Funktion sein:
\begin{itemize}
  \item{$d(x,y)=|x-y|$ bei $X=\mathbb{R}$ oder $\mathbb{C}$}
  \item{$d_2(x,y)=||x-y||_2=\sqrt{\sum_{j=1}^d (x_j-y_j)^2}$}
  \item{$d_1(x,y)=||x,y||_1=\sum_{j=1}^d|x_j-y_j|$}
  \item{$d_\infty=||x-y||_\infty=max_i|x_i-y_i|$}
\end{itemize}
\definition{Norm} Ein Normierter, Reeller Vektorraum ist ein Vektorraum $V$ uber $\mathbb{R}$ gemeinsam mit eine Abbildung $||\cdot||:V\rightarrow R_{\ge0}$ mit fonlgende Eigenschaften
\begin{itemize}
  \item{\textbf{Definitheit} $||v||=0\Leftrightarrow v=0$}
  \item{\textbf{Homogeneitat} $||tv||=|t|\cdot||v||$}
  \item{\textbf{Dreiecksungleichung} $||u+v||\le||u||+||v||$}
\end{itemize}
Diese Abbildung $||\cdot||$ wird norm genannt wenn diese Axiome $\forall v,u\in V$ gelten
\lemma{}Eine Norm auf $V$ definiert eine Metrik $d(v,w)=||v-w||$ \beweis Die Axiome der Norm passen mit dieser Definition mit den Axiomen der Metrik.
\beispiel{Paris/SNCF-Metrik}
Diese Metrik ist auf $X=\mathbb{C}$ definiert, Die Metrik bekommt ihr namen vom Fakt dass es in Frankreich mit der bahn, sehr leicht ist von irgendwo nach Paris hinzukommen, und von Paris aus irgendwo anders zu gehen.
Die Metrik ist also \[d(z,w)=\left\lbrace\begin{matrix}|z|+|w|&\text{Wenn }\not\exists \lambda\smspc w=\lambda z\\|z-w|&\text{Wenn} \exists \lambda \smspc w=\lambda z\end{matrix}\right.\]
Diese Metrik ist sehr Komisch aber respektiert immer doch die Axiome. Die Konvergenz, die bald definiert wird, hat Komische Konvergenz da sogar wenn punkte optisch sehr nah miteinander aussehen, sind die wegen der Metrik doch nicht. Deswegen, nehmen wir öftestens Normen auf Teilmengen als Metriken.
\definition{Konvergenz in einem Metrischen Raum} Sei $X$ ein Metrischer Raum, und $x_n$ eine Folge in $X$ und $z\in X$ Wir sagen dass $x_n$ gegen $z$ konvergiert und schreiben $\lim_n\rightarrow\infty x_n=z$ falls \[\forall \varepsilon>0 \exists N\smspc \forall n>N: \smspc d(x_n,z)<\varepsilon\]
\definition{Offene Ball} Sei $X$ ein Metrischer Raum. Der Offene Ball um $x_0\in X$ mit radius $r>0$ ist durch \[B_r(x_0)=\left\lbrace \left. x\in X\right|d(x,x_0)<r\right\rbrace\] definiert. Eine Menge $U\subset X$ heisst umgebung von $x_0$ falls es ein $\exists r>0$ so dass $B_r(x_0)=\subseteq U$. Mann kann auch dieser Bälle benutzen um die Konvergenz zu definieren. 
\beispiel{Der Raum der Stetigen Funktionen} Sei $a<b\in\mathbb{R}$ Wir definieren $V=C([a,b])$ ein Vektorraum. Wir definieren dann die Norm $||f||_\infty=max_{x\in[a,b]}|f(x)|$ Für eine Stetige funktion $f\in V$ Dann ist $V$ ein Reeller Vektorraum, $||\cdot||$ ist eine Norm und die Konvergenz von $f_n\in V$ gegen $f\in V$ ist gleichbedeutend zur gleichmässige Konvergenz 
\beweis Angenommen $f_n\in V$ Konvergiert für $n\rightarrow \infty$ gegen $f \in V$. Diese aussage ist analog zu:
\[\forall \varepsilon >0\smspc \exists N\in \mathbb{N} \text{ so dass } \forall n>N \smspc d(f_n,f)=||f_n-f||_\infty<\varepsilon\]
Die unendlich norm hier ist definiert wie $\max_{[a,b]}(f_n-f)$ Also gilt $\forall x\in [a,b]$\[|f_n(x)-f(x)|\le||f_n-f||_\infty<\varepsilon\] Doch den $N$ haben wir vor den $x$ gewählt, daher ist dies auch gliechmässig konvergent.
\[\forall \varepsilon< 0\smspc \exists N\in \mathbb{N}\smspc \forall n< N\smspc\forall x\in[a,b]\text{ gilt } |f_n(x)-f(x)|\le\varepsilon\]
\bemerkung{} $||\cdot||_\infty$ ist eine Norm:
\begin{itemize}
  \item[i]{$||f||_\infty=0\Longleftrightarrow f=0$}
  \item[ii]{$||\lambda f||_\infty=max_{[a,b]}|s\cdot f(x)|=|s|\cdot max_{[a,b]}|f(x)|=|s|\cdot||f||_\infty$}
  \item[iii]{$f_1,f_2\in V$ dann ist $||f_1+f_2||_\infty=max_{[a,b]}\underset{=|f_1(x)|+|f_2(x)|}{\underbrace{|f_1(x)+f_2(x)|}}\le||f_1||_\infty+||f_2||_\infty$ (dies ist nicht klar aber es beweist die Dreiecksungleichung)}
\end{itemize}
\end{document}
